{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1760012,"sourceType":"datasetVersion","datasetId":1046158}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CROP RECOMMENDATION SYSTEM\n\nA crop recommendation system helps farmers determine the best crops to plant based on various inputs such as soil quality, weather conditions, and other environmental factors. These systems contribute to improving agricultural efficiency, reducing waste, and maximizing crop yield and profit.\nIn agricultural economies where food production is critical, a well-developed crop recommendation system can greatly enhance productivity, ensuring that the right crops are grown under optimal conditions. By analyzing relevant parameters, these systems provide actionable insights that can help mitigate the risk of crop failures.\n\nThis project falls under the larger umbrella of agritech, where technological innovations are increasingly shaping the future of farming.\n\nWhy Is It Important?\n1. Precision Agriculture: This field focuses on making farming more efficient through data analysis, and crop recommendation systems are a core component.\n2. Global Impact: With growing populations, agriculture must become more efficient, making projects like this crucial for food security.\n3. Farmers' Support: Many farmers lack the tools to analyze complex environmental data, and such a system provides them with the necessary guidance.\n","metadata":{}},{"cell_type":"markdown","source":"### Importing Libraries\n* from __future__ import print_function:\nEnsures that the print() function behaves consistently across Python 2 and 3, enhancing compatibility. Useful when writing code that can be executed in both versions.\n\n* import pandas as pd:\nPandas is used for data manipulation and analysis, specifically to work with tabular data (like CSV files). It allows for easy data manipulation using DataFrames, making it central to preprocessing and analyzing crop-related datasets.\n\n* import numpy as np:\nNumPy provides support for arrays and matrices, which are fundamental for numerical computing in Python. It will be used to handle data transformations and support operations that require linear algebra or mathematical computations.\n\n* import matplotlib.pyplot as plt:\nMatplotlib is a plotting library. Itâ€™s used for creating static visualizations like line charts, histograms, and scatter plots to help understand trends in the data.\n\n* import seaborn as sns:\nSeaborn builds on Matplotlib to create more attractive and informative statistical graphics, such as heatmaps or pair plots, making it easier to explore relationships within the dataset.\n\n* from sklearn.metrics import classification_report:\nPart of scikit-learn, used for evaluating the performance of classification models, providing detailed metrics like precision, recall, and F1-score.\n\n* from sklearn import metrics, tree:\nImports tools from scikit-learn for building decision trees and evaluating model performance.\n\n* import warnings and warnings.filterwarnings('ignore'):\nSuppresses unnecessary warnings that could clutter the notebook output, ensuring a cleaner presentation.","metadata":{}},{"cell_type":"code","source":"# Importing libraries\n\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn import tree\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.365033Z","iopub.execute_input":"2024-10-13T19:16:52.365728Z","iopub.status.idle":"2024-10-13T19:16:52.376708Z","shell.execute_reply.started":"2024-10-13T19:16:52.365682Z","shell.execute_reply":"2024-10-13T19:16:52.375161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the Dataset\n* PATH = '../input/crop-recommendation-dataset/Crop_recommendation.csv':\nDefines the relative file path to the dataset (Crop_recommendation.csv) that contains the crop information.\n\n* df = pd.read_csv(PATH):\nUses Pandas to read the CSV file specified in PATH and load its contents into a DataFrame called df.\n\nPurpose: This DataFrame now holds the dataset, making it accessible for data analysis and model training in the subsequent steps.","metadata":{}},{"cell_type":"code","source":"PATH = '../input/crop-recommendation-dataset/Crop_recommendation.csv'\ndf = pd.read_csv(PATH)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.379893Z","iopub.execute_input":"2024-10-13T19:16:52.380391Z","iopub.status.idle":"2024-10-13T19:16:52.428458Z","shell.execute_reply.started":"2024-10-13T19:16:52.380343Z","shell.execute_reply":"2024-10-13T19:16:52.427421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.430421Z","iopub.execute_input":"2024-10-13T19:16:52.430966Z","iopub.status.idle":"2024-10-13T19:16:52.456546Z","shell.execute_reply.started":"2024-10-13T19:16:52.430871Z","shell.execute_reply":"2024-10-13T19:16:52.455140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.458379Z","iopub.execute_input":"2024-10-13T19:16:52.458784Z","iopub.status.idle":"2024-10-13T19:16:52.476676Z","shell.execute_reply.started":"2024-10-13T19:16:52.458743Z","shell.execute_reply":"2024-10-13T19:16:52.475294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.size","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.478496Z","iopub.execute_input":"2024-10-13T19:16:52.478885Z","iopub.status.idle":"2024-10-13T19:16:52.487332Z","shell.execute_reply.started":"2024-10-13T19:16:52.478847Z","shell.execute_reply":"2024-10-13T19:16:52.486196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.489420Z","iopub.execute_input":"2024-10-13T19:16:52.489942Z","iopub.status.idle":"2024-10-13T19:16:52.498840Z","shell.execute_reply.started":"2024-10-13T19:16:52.489891Z","shell.execute_reply":"2024-10-13T19:16:52.497784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.502986Z","iopub.execute_input":"2024-10-13T19:16:52.503364Z","iopub.status.idle":"2024-10-13T19:16:52.514338Z","shell.execute_reply.started":"2024-10-13T19:16:52.503329Z","shell.execute_reply":"2024-10-13T19:16:52.512815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploring Unique Labels\n\ndf['label'].unique():\n\nThis command extracts all unique values from the label column in the DataFrame df.\nPurpose: The label column likely represents the target variable, which in this case could be the crops. By using .unique(), it shows a list of all different crops present in the dataset, helping you understand the variety of classes (crops) the model will predict.","metadata":{}},{"cell_type":"code","source":"df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.516437Z","iopub.execute_input":"2024-10-13T19:16:52.516800Z","iopub.status.idle":"2024-10-13T19:16:52.531963Z","shell.execute_reply.started":"2024-10-13T19:16:52.516767Z","shell.execute_reply":"2024-10-13T19:16:52.530595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking Data Types\n\n#### df.dtypes:\nThis command displays the data types of each column in the DataFrame df.\nPurpose: Understanding the data types is crucial for data preprocessing and model building, as it helps to identify:\n1. Which columns are numerical (e.g., int, float) and which are categorical (e.g., object).\n2. If any data type conversions are necessary (e.g., converting categorical data to numerical form for modeling).","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.533815Z","iopub.execute_input":"2024-10-13T19:16:52.534188Z","iopub.status.idle":"2024-10-13T19:16:52.546751Z","shell.execute_reply.started":"2024-10-13T19:16:52.534151Z","shell.execute_reply":"2024-10-13T19:16:52.545495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.548339Z","iopub.execute_input":"2024-10-13T19:16:52.548684Z","iopub.status.idle":"2024-10-13T19:16:52.567366Z","shell.execute_reply.started":"2024-10-13T19:16:52.548645Z","shell.execute_reply":"2024-10-13T19:16:52.566167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Correlation with a Heatmap\n\nsns.heatmap(df.corr(), annot=True):\n* Generates a heatmap to visualize the correlation matrix of the DataFrame df.\n* df.corr() computes the pairwise correlation coefficients between numerical columns.\n* Purpose: The heatmap visually represents the strength and direction of relationships between features, helping to identify which variables are positively or negatively correlated.\n* annot=True adds the correlation values to each cell for easier interpretation.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:52.569058Z","iopub.execute_input":"2024-10-13T19:16:52.569460Z","iopub.status.idle":"2024-10-13T19:16:53.074404Z","shell.execute_reply.started":"2024-10-13T19:16:52.569413Z","shell.execute_reply":"2024-10-13T19:16:53.073279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Data for Modeling\n## Defining Features and Target:\nfeatures = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]: Selects relevant predictor variables from the DataFrame.\ntarget = df['label']: Defines the target variable (crop types) for prediction.\n\n#### Initializing Lists:\nacc = [] and model = []: Creates empty lists to store model names and their corresponding accuracies.\n\n#### Splitting Data:\nfrom sklearn.model_selection import train_test_split: Imports the function for splitting data.\nXtrain, Xtest, Ytrain, Ytest = train_test_split(features, target, test_size=0.2, random_state=2): Splits the data into training (80%) and testing (20%) sets for model training and evaluation.\nPurpose: This cell prepares the dataset for machine learning by defining the features and target, initializing lists for model performance tracking, and splitting the data into training and testing subsets.","metadata":{}},{"cell_type":"code","source":"features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\ntarget = df['label']\nlabels = df['label']","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.076687Z","iopub.execute_input":"2024-10-13T19:16:53.077196Z","iopub.status.idle":"2024-10-13T19:16:53.086406Z","shell.execute_reply.started":"2024-10-13T19:16:53.077145Z","shell.execute_reply":"2024-10-13T19:16:53.085303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initializing empty lists to append all model's name and corresponding name\nacc = []\nmodel = []","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.090467Z","iopub.execute_input":"2024-10-13T19:16:53.090896Z","iopub.status.idle":"2024-10-13T19:16:53.099695Z","shell.execute_reply.started":"2024-10-13T19:16:53.090858Z","shell.execute_reply":"2024-10-13T19:16:53.098410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting into train and test data\n\nfrom sklearn.model_selection import train_test_split\nXtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.103851Z","iopub.execute_input":"2024-10-13T19:16:53.104379Z","iopub.status.idle":"2024-10-13T19:16:53.118701Z","shell.execute_reply.started":"2024-10-13T19:16:53.104337Z","shell.execute_reply":"2024-10-13T19:16:53.117596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"markdown","source":"#### Implementing a Decision Tree Classifier\n* Model Creation: A decision tree classifier is initialized with parameters for evaluating splits, controlling randomness, and limiting depth to avoid overfitting.\n* Training: The model is trained on the training data to learn relationships between features and crop types.\n* Prediction: The trained model predicts crop types for the test dataset.\n* Accuracy Evaluation: The accuracy of the predictions is calculated and stored for comparison with other models.\n* Classification Report: A report is generated showing precision, recall, and F1-score for each crop type, offering a comprehensive performance assessment.\n\nPurpose: This cell builds and evaluates a Decision Tree classifier for predicting crop types based on environmental features.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nDecisionTree = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n\nDecisionTree.fit(Xtrain,Ytrain)\n\npredicted_values = DecisionTree.predict(Xtest)\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('Decision Tree')\nprint(\"DecisionTrees's Accuracy is: \", x*100)\n\nprint(classification_report(Ytest,predicted_values))","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.121010Z","iopub.execute_input":"2024-10-13T19:16:53.121514Z","iopub.status.idle":"2024-10-13T19:16:53.196681Z","shell.execute_reply.started":"2024-10-13T19:16:53.121464Z","shell.execute_reply":"2024-10-13T19:16:53.195352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross-Validation Import: Imports cross_val_score from scikit-learn to evaluate the model's performance.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.198470Z","iopub.execute_input":"2024-10-13T19:16:53.198901Z","iopub.status.idle":"2024-10-13T19:16:53.204159Z","shell.execute_reply.started":"2024-10-13T19:16:53.198863Z","shell.execute_reply":"2024-10-13T19:16:53.202905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross-Validation Execution: The cross_val_score function calculates the accuracy of the Decision Tree classifier using 5-fold cross-validation on the entire dataset.","metadata":{}},{"cell_type":"code","source":"# Cross validation score (Decision Tree)\nscore = cross_val_score(DecisionTree, features, target,cv=5)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.205932Z","iopub.execute_input":"2024-10-13T19:16:53.206449Z","iopub.status.idle":"2024-10-13T19:16:53.385598Z","shell.execute_reply.started":"2024-10-13T19:16:53.206397Z","shell.execute_reply":"2024-10-13T19:16:53.384538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score Output: The resulting scores represent the model's accuracy across different subsets of the data.","metadata":{}},{"cell_type":"code","source":"score","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.387151Z","iopub.execute_input":"2024-10-13T19:16:53.387707Z","iopub.status.idle":"2024-10-13T19:16:53.394341Z","shell.execute_reply.started":"2024-10-13T19:16:53.387658Z","shell.execute_reply":"2024-10-13T19:16:53.393204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the Decision Tree Model\n\n* Importing Pickle: The pickle library is imported for serializing and saving Python objects.\n\n* Model Filename: A filename (DecisionTree.pkl) is specified for saving the trained Decision Tree model.\n\n* Opening a File: A file is opened in write-binary mode ('wb') to create a new file for storing the model.\n\n* Saving the Model: The trained Decision Tree model is serialized and saved to the file using pickle.dump(), which allows for later retrieval and use without needing to retrain.\n\n* Closing the File: The file is closed to ensure that all data is properly written and resources are released.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nDT_pkl_filename = 'DecisionTree.pkl'\n# Open the file to save as pkl file\nDT_Model_pkl = open(DT_pkl_filename, 'wb')\npickle.dump(DecisionTree, DT_Model_pkl)\n# Close the pickle instances\nDT_Model_pkl.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.395854Z","iopub.execute_input":"2024-10-13T19:16:53.396299Z","iopub.status.idle":"2024-10-13T19:16:53.406847Z","shell.execute_reply.started":"2024-10-13T19:16:53.396252Z","shell.execute_reply":"2024-10-13T19:16:53.405697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Guassian Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nNaiveBayes = GaussianNB()\n\nNaiveBayes.fit(Xtrain,Ytrain)\n\npredicted_values = NaiveBayes.predict(Xtest)\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('Naive Bayes')\nprint(\"Naive Bayes's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.408554Z","iopub.execute_input":"2024-10-13T19:16:53.408949Z","iopub.status.idle":"2024-10-13T19:16:53.455437Z","shell.execute_reply.started":"2024-10-13T19:16:53.408910Z","shell.execute_reply":"2024-10-13T19:16:53.454146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation score (NaiveBayes)\nscore = cross_val_score(NaiveBayes,features,target,cv=5)\nscore","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.456894Z","iopub.execute_input":"2024-10-13T19:16:53.457238Z","iopub.status.idle":"2024-10-13T19:16:53.552633Z","shell.execute_reply.started":"2024-10-13T19:16:53.457181Z","shell.execute_reply":"2024-10-13T19:16:53.551463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving trained Guassian Naive Bayes model","metadata":{}},{"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nNB_pkl_filename = 'NBClassifier.pkl'\n# Open the file to save as pkl file\nNB_Model_pkl = open(NB_pkl_filename, 'wb')\npickle.dump(NaiveBayes, NB_Model_pkl)\n# Close the pickle instances\nNB_Model_pkl.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.554113Z","iopub.execute_input":"2024-10-13T19:16:53.554475Z","iopub.status.idle":"2024-10-13T19:16:53.562769Z","shell.execute_reply.started":"2024-10-13T19:16:53.554439Z","shell.execute_reply":"2024-10-13T19:16:53.561137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing a Support Vector Machine (SVM) Classifier\n\n* Model Introduction: The cell begins by indicating the implementation of a Support Vector Machine (SVM) classifier.\n\n* Importing the Classifier: The SVC (Support Vector Classification) from the scikit-learn library is imported for building the SVM model.\n\n* Creating the Model: An instance of SVC is initialized with the parameter gamma='auto', which controls the influence of individual training examples on the decision boundary.\n\n* Fitting the Model: The SVM model is trained using the training dataset (Xtrain for features and Ytrain for labels). This step allows the model to learn how to classify the data based on the given features.\n\n* Making Predictions: The trained SVM model predicts crop types for the test dataset (Xtest), and the results are stored in predicted_values.\n\n* Evaluating Model Accuracy: The accuracy of the predictions is calculated by comparing the predicted values to the actual test labels (Ytest). The accuracy score is appended to the acc list for further comparison.\n\n* Printing Accuracy: The accuracy score is printed, providing a measure of the model's performance.\n\n* Generating Classification Report: A classification report is generated, detailing metrics such as precision, recall, and F1-score for each crop type, allowing for a thorough evaluation of the model's performance.\n\n#### Purpose: This cell trains and evaluates a Support Vector Machine classifier, providing insights into its accuracy and effectiveness in predicting crop types based on environmental features.\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nSVM = SVC(gamma='auto')\n\nSVM.fit(Xtrain,Ytrain)\n\npredicted_values = SVM.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('SVM')\nprint(\"SVM's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:53.565174Z","iopub.execute_input":"2024-10-13T19:16:53.565619Z","iopub.status.idle":"2024-10-13T19:16:54.003191Z","shell.execute_reply.started":"2024-10-13T19:16:53.565582Z","shell.execute_reply":"2024-10-13T19:16:54.002080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation score (SVM)\nscore = cross_val_score(SVM,features,target,cv=5)\nscore","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:54.004923Z","iopub.execute_input":"2024-10-13T19:16:54.005712Z","iopub.status.idle":"2024-10-13T19:16:55.892092Z","shell.execute_reply.started":"2024-10-13T19:16:54.005638Z","shell.execute_reply":"2024-10-13T19:16:55.890796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing Logistic Regression\n\n* Model Introduction: The cell begins by indicating the implementation of a Logistic Regression classifier.\n\n* Importing the Classifier: The LogisticRegression class from the scikit-learn library is imported for creating the logistic regression model.\n\n* Creating the Model: An instance of LogisticRegression is initialized with a parameter for random_state=2, which ensures that the results are reproducible.\n\n* Fitting the Model: The logistic regression model is trained on the training dataset, using Xtrain for the features and Ytrain for the target labels. This allows the model to learn how to make predictions based on the input data.\n\n* Making Predictions: The trained model is used to predict crop types for the test dataset (Xtest), and the results are stored in predicted_values.\n\n* Evaluating Model Accuracy: The accuracy of the predictions is calculated by comparing the predicted values against the actual test labels (Ytest). The accuracy score is appended to the acc list for future comparison.\n\n* Printing Accuracy: The accuracy score is printed, providing a measure of how well the logistic regression model performed.\n\n* Generating Classification Report: A classification report is produced, detailing metrics such as precision, recall, and F1-score for each crop type, allowing for an in-depth evaluation of the model's performance.\n\n#### Purpose: This cell trains and evaluates a Logistic Regression classifier, offering insights into its accuracy and overall effectiveness in predicting crop types based on environmental features.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nLogReg = LogisticRegression(random_state=2)\n\nLogReg.fit(Xtrain,Ytrain)\n\npredicted_values = LogReg.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('Logistic Regression')\nprint(\"Logistic Regression's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:55.893642Z","iopub.execute_input":"2024-10-13T19:16:55.893996Z","iopub.status.idle":"2024-10-13T19:16:56.255844Z","shell.execute_reply.started":"2024-10-13T19:16:55.893961Z","shell.execute_reply":"2024-10-13T19:16:56.254849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation score (Logistic Regression)\nscore = cross_val_score(LogReg,features,target,cv=5)\nscore","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:56.257435Z","iopub.execute_input":"2024-10-13T19:16:56.257814Z","iopub.status.idle":"2024-10-13T19:16:58.248056Z","shell.execute_reply.started":"2024-10-13T19:16:56.257777Z","shell.execute_reply":"2024-10-13T19:16:58.247017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving trained Logistic Regression model\n\n* Importing Pickle: The pickle library is imported to handle the serialization of Python objects, enabling saving and loading of models.\n\n* Model Filename: A filename (LogisticRegression.pkl) is specified for saving the trained logistic regression model.\n\n* Opening a File: A file is opened in write-binary mode ('wb') to create a new file for storing the model.\n\n* Saving the Model: The trained logistic regression model is serialized and saved to the file using pickle.dump(). This allows the model to be reused later without needing to retrain it.\n\n* Closing the File: The file is closed to ensure that all data is properly written and resources are released.\n\n#### Purpose: This cell saves the trained Logistic Regression model to a file, facilitating its reuse in future sessions without the need for retraining, which is efficient for deployment and testing.","metadata":{}},{"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nLR_pkl_filename = 'LogisticRegression.pkl'\n# Open the file to save as pkl file\nLR_Model_pkl = open(DT_pkl_filename, 'wb')\npickle.dump(LogReg, LR_Model_pkl)\n# Close the pickle instances\nLR_Model_pkl.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:58.249742Z","iopub.execute_input":"2024-10-13T19:16:58.250475Z","iopub.status.idle":"2024-10-13T19:16:58.257872Z","shell.execute_reply.started":"2024-10-13T19:16:58.250423Z","shell.execute_reply":"2024-10-13T19:16:58.256693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing a Random Forest Classifier\n\n* Model Introduction: The cell begins by indicating the implementation of a Random Forest classifier.\n\n* Importing the Classifier: The RandomForestClassifier from the scikit-learn library is imported to create the random forest model.\n\n* Creating the Model: An instance of RandomForestClassifier is initialized with parameters, including n_estimators=20, which specifies the number of trees in the forest, and random_state=0 for reproducibility.\n\n* Fitting the Model: The random forest model is trained using the training dataset (Xtrain for features and Ytrain for labels). This training process allows the model to learn patterns in the data.\n\n* Making Predictions: The trained model predicts crop types for the test dataset (Xtest), with the predicted values stored in predicted_values.\n\n* Evaluating Model Accuracy: The accuracy of the predictions is calculated by comparing the predicted values to the actual labels in the test dataset (Ytest). This accuracy score is appended to the acc list for later comparison.\n\n* Printing Accuracy: The accuracy score is printed, providing a quantitative measure of how well the random forest model performed.\n\n* Generating Classification Report: A classification report is generated, detailing metrics such as precision, recall, and F1-score for each crop type, allowing for a comprehensive evaluation of the model's performance.\n\n#### Purpose: This cell trains and evaluates a Random Forest classifier, providing insights into its accuracy and effectiveness in predicting crop types based on environmental features.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRF = RandomForestClassifier(n_estimators=20, random_state=0)\nRF.fit(Xtrain,Ytrain)\n\npredicted_values = RF.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('RF')\nprint(\"RF's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:58.259800Z","iopub.execute_input":"2024-10-13T19:16:58.260714Z","iopub.status.idle":"2024-10-13T19:16:58.416595Z","shell.execute_reply.started":"2024-10-13T19:16:58.260657Z","shell.execute_reply":"2024-10-13T19:16:58.415016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation score (Random Forest)\nscore = cross_val_score(RF,features,target,cv=5)\nscore","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:58.418422Z","iopub.execute_input":"2024-10-13T19:16:58.418801Z","iopub.status.idle":"2024-10-13T19:16:58.967786Z","shell.execute_reply.started":"2024-10-13T19:16:58.418761Z","shell.execute_reply":"2024-10-13T19:16:58.966708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving trained Random Forest model","metadata":{}},{"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nRF_pkl_filename = 'RandomForest.pkl'\n# Open the file to save as pkl file\nRF_Model_pkl = open(RF_pkl_filename, 'wb')\npickle.dump(RF, RF_Model_pkl)\n# Close the pickle instances\nRF_Model_pkl.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:58.969275Z","iopub.execute_input":"2024-10-13T19:16:58.969636Z","iopub.status.idle":"2024-10-13T19:16:58.979192Z","shell.execute_reply.started":"2024-10-13T19:16:58.969600Z","shell.execute_reply":"2024-10-13T19:16:58.977924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost\n\nThis cell implements an XGBoost classifier to predict crop types based on environmental features. It begins by importing the XGBClassifier from the xgboost library and then initializes the model. The classifier is trained on the training dataset using Xtrain for features and Ytrain for labels, allowing it to learn the underlying patterns in the data. After training, the model makes predictions on the test dataset (Xtest), and the accuracy of these predictions is calculated by comparing them to the actual labels in Ytest. This accuracy score is appended to the acc list for further analysis. Finally, the accuracy score is printed, and a classification report is generated, providing metrics such as precision, recall, and F1-score for each crop type, which helps assess the model's performance in making accurate predictions.","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nXB = xgb.XGBClassifier()\nXB.fit(Xtrain,Ytrain)\n\npredicted_values = XB.predict(Xtest)\n\nx = metrics.accuracy_score(Ytest, predicted_values)\nacc.append(x)\nmodel.append('XGBoost')\nprint(\"XGBoost's Accuracy is: \", x)\n\nprint(classification_report(Ytest,predicted_values))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-13T19:16:58.980804Z","iopub.execute_input":"2024-10-13T19:16:58.981185Z","iopub.status.idle":"2024-10-13T19:16:59.577080Z","shell.execute_reply.started":"2024-10-13T19:16:58.981148Z","shell.execute_reply":"2024-10-13T19:16:59.576108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation score (XGBoost)\nscore = cross_val_score(XB,features,target,cv=5)\nscore","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:16:59.578765Z","iopub.execute_input":"2024-10-13T19:16:59.579437Z","iopub.status.idle":"2024-10-13T19:17:02.314132Z","shell.execute_reply.started":"2024-10-13T19:16:59.579391Z","shell.execute_reply":"2024-10-13T19:17:02.313122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving trained XGBoost model","metadata":{}},{"cell_type":"code","source":"import pickle\n# Dump the trained Naive Bayes classifier with Pickle\nXB_pkl_filename = 'XGBoost.pkl'\n# Open the file to save as pkl file\nXB_Model_pkl = open(XB_pkl_filename, 'wb')\npickle.dump(XB, XB_Model_pkl)\n# Close the pickle instances\nXB_Model_pkl.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:17:02.315858Z","iopub.execute_input":"2024-10-13T19:17:02.316557Z","iopub.status.idle":"2024-10-13T19:17:02.327053Z","shell.execute_reply.started":"2024-10-13T19:17:02.316511Z","shell.execute_reply":"2024-10-13T19:17:02.325964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy Comparison\n\nThis cell visualizes the accuracy of different classification algorithms used to predict crop types. A bar plot is created using Seaborn, with the x-axis representing accuracy scores and the y-axis displaying the names of the models. The plot is titled \"Accuracy Comparison,\" enabling a quick visual assessment of which algorithm performed best in terms of accuracy.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[10,5],dpi = 100)\nplt.title('Accuracy Comparison')\nplt.xlabel('Accuracy')\nplt.ylabel('Algorithm')\nsns.barplot(x = acc,y = model,palette='dark')","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:17:02.328902Z","iopub.execute_input":"2024-10-13T19:17:02.329684Z","iopub.status.idle":"2024-10-13T19:17:02.568118Z","shell.execute_reply.started":"2024-10-13T19:17:02.329631Z","shell.execute_reply":"2024-10-13T19:17:02.567088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_models = dict(zip(model, acc))\nfor k, v in accuracy_models.items():\n    print (k, '-->', v)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:17:02.569559Z","iopub.execute_input":"2024-10-13T19:17:02.569894Z","iopub.status.idle":"2024-10-13T19:17:02.577879Z","shell.execute_reply.started":"2024-10-13T19:17:02.569860Z","shell.execute_reply":"2024-10-13T19:17:02.576884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making Predictions\n\n* Define Input Data: An input array is created to represent specific environmental conditions, including values for nitrogen, phosphorus, potassium, temperature, humidity, pH, and rainfall.\n\n* Make Prediction: The Random Forest model is used to predict the crop type based on the defined environmental conditions by calling its prediction method.\n\n* Print Prediction: The predicted crop type is displayed, indicating the model's recommendation for the given parameters.\n\n* Repeat for New Data: A second input array is defined with a different set of environmental conditions.\n\n* Make Second Prediction: The model's prediction method is called again with the new input data to generate another prediction.\n\n* Print Second Prediction: The predicted crop type for the second set of conditions is displayed.\n\n#### Purpose: This cell showcases how to utilize the trained Random Forest model to provide crop type recommendations based on varying agricultural inputs.","metadata":{}},{"cell_type":"code","source":"data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])\nprediction = RF.predict(data)\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:17:02.579236Z","iopub.execute_input":"2024-10-13T19:17:02.579612Z","iopub.status.idle":"2024-10-13T19:17:02.596855Z","shell.execute_reply.started":"2024-10-13T19:17:02.579562Z","shell.execute_reply":"2024-10-13T19:17:02.595356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\nprediction = RF.predict(data)\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:17:02.601540Z","iopub.execute_input":"2024-10-13T19:17:02.601940Z","iopub.status.idle":"2024-10-13T19:17:02.612999Z","shell.execute_reply.started":"2024-10-13T19:17:02.601902Z","shell.execute_reply":"2024-10-13T19:17:02.611609Z"},"trusted":true},"execution_count":null,"outputs":[]}]}